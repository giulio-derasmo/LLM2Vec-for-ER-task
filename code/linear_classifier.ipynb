{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c79334-105e-43d3-b052-76229c472401",
   "metadata": {},
   "source": [
    "### Load libr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af1b8d9e-07fc-4a18-8c7f-95b22d56bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# standard libr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aa81d9b-7c11-4ad9-a8a3-7ce74878137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## csv files\n",
    "dataset_table_dir_path = \"data/datasets\"\n",
    "datasets_path = [os.path.join(dataset_name, 'exp_data') for dataset_name in os.listdir(dataset_table_dir_path)]\n",
    "datasets_name = [x.split('\\\\')[0] for x in datasets_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e1c370-d54e-4be1-91e9-6e5503912015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abt_buy_exp_data',\n",
       " 'dirty_dblp_acm_exp_data',\n",
       " 'dirty_dblp_scholar_exp_data',\n",
       " 'dirty_itunes_amazon_exp_data',\n",
       " 'dirty_walmart_amazon_exp_data']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78279b-6e23-4005-8eab-982594528375",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0ae403-9050-465e-b4fd-c47e98e7036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'embeddings/train_test'\n",
    "\n",
    "train_path = os.path.join(dir_path, datasets_name[0], 'train')\n",
    "train_files = glob.glob(f'{train_path}/*.pt')\n",
    "valid_path = os.path.join(dir_path, datasets_name[0], 'valid')\n",
    "valid_files = glob.glob(f'{valid_path}/*.pt')\n",
    "\n",
    "train = pd.read_csv(os.path.join('data/datasets', datasets_name[0], 'exp_data/train.csv'))\n",
    "valid = pd.read_csv(os.path.join('data/datasets', datasets_name[0], 'exp_data/valid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68223c76-9976-4bcb-b294-a43548eaa510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ltable_id</th>\n",
       "      <th>rtable_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>733</td>\n",
       "      <td>716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>619</td>\n",
       "      <td>716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>561</td>\n",
       "      <td>716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>715</td>\n",
       "      <td>716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>546</td>\n",
       "      <td>716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>713</td>\n",
       "      <td>716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ltable_id  rtable_id  label\n",
       "716         733        716      0\n",
       "934         619        716      0\n",
       "1764        561        716      0\n",
       "1778        715        716      0\n",
       "1786        546        716      0\n",
       "1830        713        716      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[valid.rtable_id == 716]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95939c1c-9f86-4f49-ab4e-867212891b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mappingA = pd.read_pickle('embeddings/train_test/mappings/mapping_split_train_ds_abt_buy_table_tableA_with_labels_0.pickle')\n",
    "train_mappingA = {v:k for k,v in train_mappingA.items()}\n",
    "\n",
    "train_mappingB = pd.read_pickle('embeddings/train_test/mappings/mapping_split_train_ds_abt_buy_table_tableB_with_labels_0.pickle')\n",
    "train_mappingB = {v:k for k,v in train_mappingB.items()}\n",
    "\n",
    "valid_mappingA = pd.read_pickle('embeddings/train_test/mappings/mapping_split_valid_ds_abt_buy_table_tableA_with_labels_0.pickle')\n",
    "valid_mappingA = {v:k for k,v in valid_mappingA.items()}\n",
    "\n",
    "valid_mappingB = pd.read_pickle('embeddings/train_test/mappings/mapping_split_valid_ds_abt_buy_table_tableB_with_labels_0.pickle')\n",
    "valid_mappingB = {v:k for k,v in valid_mappingB.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5eacbf2-f5c7-4dc1-8aea-3f6fa852c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableA_train = torch.from_numpy(torch.load(train_files[0]))\n",
    "tableB_train = torch.from_numpy(torch.load(train_files[1]))\n",
    "\n",
    "tableA_valid = torch.from_numpy(torch.load(valid_files[0]))\n",
    "tableB_valid = torch.from_numpy(torch.load(valid_files[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4387edb-7e08-4fe7-bf74-fbf106c1f4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([973, 4096]),\n",
       " torch.Size([956, 4096]),\n",
       " torch.Size([728, 4096]),\n",
       " torch.Size([702, 4096]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableA_train.shape, tableB_train.shape, tableA_valid.shape, tableB_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4412b3b-294b-4b2c-95e1-6a91538201e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = train.apply(lambda pair: torch.concat([tableA_train[train_mappingA[pair['ltable_id']]],\n",
    "                                                    tableB_train[train_mappingB[pair['rtable_id']]]]), axis = 1)\n",
    "X_tr = torch.stack(list(X_tr.values), axis = 0)\n",
    "\n",
    "X_val = valid.apply(lambda pair: torch.concat([tableA_valid[valid_mappingA[pair['ltable_id']]],\n",
    "                                                  tableB_valid[valid_mappingB[pair['rtable_id']]]]), axis = 1)\n",
    "X_val = torch.stack(list(X_val.values), axis = 0)\n",
    "\n",
    "y_tr = torch.tensor(train.label)\n",
    "y_val = torch.tensor(valid.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a988411-b929-4123-9ab0-f76b04feba0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5743, 8192]),\n",
       " torch.Size([1916, 8192]),\n",
       " torch.Size([5743]),\n",
       " torch.Size([1916]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_val.shape, y_tr.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0b8909ce-b44c-4253-b796-30d52f713924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7e94f760-e994-4936-b2e7-43fceced68ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_tr, y_tr) \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers = 15) \n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val) \n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128, num_workers = 15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "144e9711-c7a9-42de-96d2-827d1bbf1d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer, seed_everything\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "89e478b6-8874-4451-88e0-985b625cb613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyLitModel(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.model = Model(input_size, hidden_size, output_size)\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out, y.view(-1, 1))\n",
    "        self.log('train_loss', loss)\n",
    "        f1 = f1_score( (out>=0.5).int().cpu().numpy(), y.cpu().numpy())\n",
    "        self.log(\"train_f1\", f1)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out, y.view(-1, 1))\n",
    "        self.log(\"val_loss\", loss)\n",
    "        f1 = f1_score( (out>=0.5).int().cpu().numpy(), y.cpu().numpy())\n",
    "        self.log(\"val_f1\", f1)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f93cf04f-f83e-407e-a2d5-8de457795068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping('val_f1', patience=5, mode = 'max')\n",
    "trainer = pl.Trainer(max_epochs=50, devices=1, accelerator=\"gpu\", callbacks=early_stopping)\n",
    "model = MyLitModel(input_size = 2*4096, hidden_size = 512, output_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982f8f0-7f9c-4086-911c-c73feaa7cbf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99905e43-80de-40d4-9885-ef4c38b7d291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
